{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de487b3",
   "metadata": {},
   "source": [
    "# iPython Notebook for Training a New Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee7142",
   "metadata": {},
   "source": [
    "## This iPython notebook details code for training. \n",
    "\n",
    "Note: To train these models will require a GPU and cannot be done with a CPU. In addition, it is highly recommended that the user creates a new python file using this notebook as a guide. Training using a Jupyter Notebook is not recommended "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a231a",
   "metadata": {},
   "source": [
    "## Please make sure the following files are in the directory in which you are training from: \n",
    "1. training.py \n",
    "2. unet3d.py\n",
    "3. cunet3d.py\n",
    "4. unetplusplus3d.py\n",
    "5. testing3D.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241d24a",
   "metadata": {},
   "source": [
    "## Please label your data as follows: \n",
    "\n",
    "### Training Data \n",
    "1. Training Data - scar_imgs_train.npy\n",
    "2. Training Segmentations - scar_segs_train.npy\n",
    "\n",
    "### Validation Data \n",
    "1. Validation Data - scar_imgs_val.npy\n",
    "2. Validation Segmentations - scar_imgs_val.npy\n",
    "\n",
    "For data normalization, it is recommended that you use the mean intensity of your training data. Please save this \n",
    "number as: scar_shift.npy\n",
    "\n",
    "\n",
    "#### Training and Validation Data Dimensions: \n",
    "\n",
    "Please ensure your training data is of the format: (N_studies,256,256,16). Unfortunately, the only compatible size is 256x256x16. This will be corrected in future releases. \n",
    "\n",
    "Please ensure your segmentation data is of the format: (N_studies,256,256,16,3). The channels are 0 - Background Voxels, 1 - Myocardial Voxels, 2 - Scar Voxels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629cdecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 08:27:28.468896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries \n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "# Keras Libraries \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# My libraries \n",
    "from unet3d import get_unet3D_multi \n",
    "from cunet3d import get_Cunet3D_mulit\n",
    "from unetplusplus3d import get_unetpp3D_multi\n",
    "\n",
    "from training import training_main \n",
    "from testing3D import testing_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f24a03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# DEFINE PATH WHERE DATA IS HERE: \n",
    "dpath = # Input path here \n",
    "\n",
    "print('*'*100)\n",
    "print('LOADING DATA')\n",
    "\n",
    "shift = np.load(dpath+'scar_mean.npy')\n",
    "\n",
    "imgs_train = np.load(dpath+'scar_imgs_train.npy')\n",
    "imgs_val = np.load(dpath+'scar_imgs_test.npy')\n",
    "segs_train = np.load(dpath+'scar_segs_train.npy')\n",
    "segs_val = np.load(dpath+'scar_segs_test.npy')\n",
    "\n",
    "img_rows = imgs_train.shape[1]\n",
    "img_cols = imgs_train.shape[2]\n",
    "slices = imgs_train.shape[3]\n",
    "print('*'*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PATH WHERE YOU WOULD LIKE TO SAVE LEARNING CURVES AND WEIGHTS \n",
    "\n",
    "path1 = # Input path for saving here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER SELECTION \n",
    "\n",
    "# Model Parameters \n",
    "classes = 3 \n",
    "layers = 4 # INPUT NUMBER OF LAYERS. AT THIS TIME, THIS ONLY APPLIES TO THE U-NET MODEL \n",
    "min_convs = 4 # THIS SETS THE MINIMUM NUMBER OF CONVOLUTIONS IN THE BOTTOM LAYER \n",
    "kernel = (3,3,3) # DO NOT CHANGE \n",
    "\n",
    "''' \n",
    "For loss functions, you have the following options: \n",
    "1. wcce_kld (Weighted Adaptive Categorical Entropy with KL Divergence) - THIS WAS USED IN THE MANUSCRIPT \n",
    "2. dice_loss (Dice Coefficient Loss)\n",
    "3. dice_gen_loss (Generalized Dice Coefficient Loss)\n",
    "4. weighted_categorical_crossentropy (Weighted Adaptive Categorical Cross Entropy)\n",
    "5. categorical_crossentropy (Adaptive Categorical Cross Entropy. DEFAULT if none of the other options are input) \n",
    "'''\n",
    "lossfun = 'wcce_kld'\n",
    "\n",
    "# Hyperparameters \n",
    "learning_rate = 1e-5 # LEARNING RATE \n",
    "decay = 0.6 # DECAY RATE FOR ADAPTIVE CROSS ENTROPY \n",
    "batches = 4 # BATCH SIZE \n",
    "epochs_total = 30 # TOTAL NUMBER OF EPOCHS \n",
    "epochs_batch = 5 # BATCHES PER EPOCH \n",
    "weights_init = (1,14,48) # WEIGHTS IF USING WEIGHTED CROSS ENTROPY \n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "train_loss = np.zeros((epochs_total,))\n",
    "train_dice = np.zeros((epochs_total,))\n",
    "train_myo = np.zeros((epochs_total,))\n",
    "\n",
    "val_loss = np.zeros((epochs_total,))\n",
    "val_dice = np.zeros((epochs_total,))\n",
    "val_myo = np.zeros((epochs_total,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER MODEL TYPE SELECTION AND MODEL DEFINITION \n",
    "\n",
    "model_type = # User can input the models. The selection is: U-Net, Cascaded U-Net, U-Net++. Please input the name of the model of choice here. \n",
    "\n",
    "if model_type == \"U-Net\": \n",
    "    with strategy.scope():\n",
    "        model = get_unet3D_multi(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "    model.summary()\n",
    "elif model_type == \"Cascaded U-Net\": \n",
    "    with strategy.scope():\n",
    "        model = get_Cunet3D_mulit(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "    model.summary()\n",
    "    path1 = \"weights_cunet.h5\": \n",
    "elif model_type == \"U-Net++\": \n",
    "    with strategy.scope():\n",
    "        model = get_unetpp3D_multi(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "    model.summary()\n",
    "else: \n",
    "    print('Please enter one of the appropriate options: U-Net, Cascaded U-Net, or U-Net++')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING \n",
    "\n",
    "savepath1 = path1[:-1]\n",
    "savepath1 = savepath1+\"_batch1/\"\n",
    "cache = training_main(imgs_train,segs_train,model,savepath1, batches, epochs_batch, imgs_val, segs_val)\n",
    "num_epoch_batches = int(np.round(epochs_total/epochs_batch))\n",
    "\n",
    "train_loss[0:epochs_batch] = np.array(cache.history['loss'])\n",
    "train_dice[0:epochs_batch] = np.array(cache.history['dice_coef'])\n",
    "train_myo[0:epochs_batch] = np.array(cache.history['myo_dice'])\n",
    "\n",
    "val_loss[0:epochs_batch] = np.array(cache.history['val_loss'])\n",
    "val_dice[0:epochs_batch] = np.array(cache.history['val_dice_coef'])\n",
    "val_myo[0:epochs_batch] = np.array(cache.history['val_myo_dice'])\n",
    "\n",
    "for ii in range(num_epoch_batches - 1): \n",
    "    weights1 = (weights_init[1]-1)*np.exp(-ii*decay) + 1 \n",
    "    weights2= (weights_init[2]-1)*np.exp(-ii*decay) + 1\n",
    "    \n",
    "    weights = (weights_init[0],weights1,weights2)\n",
    "    \n",
    "    if model_type == \"U-Net\": \n",
    "        with strategy.scope():\n",
    "            model = get_unet3D_multi(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "        model.summary()\n",
    "    elif model_type == \"Cascaded U-Net\": \n",
    "        with strategy.scope():\n",
    "            model = get_Cunet3D_mulit(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "        model.summary()\n",
    "        path1 = \"weights_cunet.h5\": \n",
    "    elif model_type == \"U-Net++\": \n",
    "        with strategy.scope():\n",
    "            model = get_unetpp3D_multi(img_rows, img_cols, slices, classes, layers, min_convs, kernel, learning_rate, lossfun, weights_init)\n",
    "\n",
    "    old_model_weight_path = savepath1 + 'final_weights.h5'\n",
    "    model.load_weights(old_model_weight_path)\n",
    "    \n",
    "    ind1 = epochs_batch*(ii+1)\n",
    "    ind2 = epochs_batch*(ii+2)\n",
    "    \n",
    "    print('-'*100)\n",
    "    print('Training Epochs'+str(ind1)+\"-\"+str(ind2))\n",
    "    print('-'*100)\n",
    "    pathii = path1[:-1]\n",
    "    pathii = pathii+\"_batch\"+str(ii+2)+\"/\"\n",
    "    cache = training_main(imgs_train,segs_train,model,pathii, batches, epochs_batch, imgs_val, segs_val)\n",
    "    \n",
    "    \n",
    "    train_loss[ind1:ind2] = np.array(cache.history['loss'])\n",
    "    train_dice[ind1:ind2] = np.array(cache.history['dice_coef'])\n",
    "    train_myo[ind1:ind2] = np.array(cache.history['myo_dice'])\n",
    "\n",
    "    val_loss[ind1:ind2] = np.array(cache.history['val_loss'])\n",
    "    val_dice[ind1:ind2] = np.array(cache.history['val_dice_coef'])\n",
    "    val_myo[ind1:ind2] = np.array(cache.history['val_myo_dice'])\n",
    "    \n",
    "\n",
    "np.save(path1+'train_loss.npy',train_loss)\n",
    "np.save(path1+'train_dice.npy',train_dice)\n",
    "np.save(path1+'train_myo.npy',train_myo)\n",
    "\n",
    "np.save(path1+'val_loss.npy',val_loss)\n",
    "np.save(path1+'val_dice.npy',val_dice)\n",
    "np.save(path1+'val_myo.npy',val_myo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a31549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE RESULTS OF THE VALIDATION DATA SET \n",
    "\n",
    "savepath = pathii+'validation/'\n",
    "\n",
    "# Create the path \n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "gpus = 1 \n",
    "\n",
    "# Testing model on validation set only \n",
    "preds, contours = testing_parallel(savepath, model, imgs_val, segs_val, gpus, classes, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80811d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING REPRESENTATIVE SEGMENTATION MASKS \n",
    "\n",
    "m = # INPUT WHICH STUDY NUMBER YOU WOULD LIKE TO PLOT. IF YOU ONLY HAVE 1 STUDY, then m = 1 \n",
    "\n",
    "for ii in range(16): \n",
    "    plt.subplot(4,4,ii+1)\n",
    "    plt.imshow(preds[m,:,:,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING REPRESENTATIVE SEGMENTATION MASKS \n",
    "\n",
    "m = # INPUT WHICH STUDY NUMBER YOU WOULD LIKE TO PLOT. IF YOU ONLY HAVE 1 STUDY, then m = 1 \n",
    "\n",
    "for ii in range(16): \n",
    "    plt.subplot(4,4,ii+1)\n",
    "    plt.imshow(contours[m,:,:,:,:])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
